20-10-2022
- Problema con el acceso, es necesario pedir el Elevado para poder usar el método search_tweets de API Tweepy: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets

26-10-2022
- Para poder recuperar el tweet de forma completa es necesario añadir el argumento tweet_mode='extended': https://docs.tweepy.org/en/stable/extended_tweets.html
- Para recuperar descartar los rt y quedarnos solo con un tweet añadimos el flag -filter:retweets al argumento en el que se le pasa la query: https://stackoverflow.com/questions/71746985/is-there-a-way-to-filter-out-retweets-from-results-of-search-tweets-using-tweepy

27-10-2022
-Busco una solución para traduccir los tweets de cualquier idioma al inglés. Intento usar una llamada API al servicio de Google Translate pero se obtiene constantemente el fallo 'HTTP Error 429: Too Many Requests'. Finalmente usamos la librería de python googletrans para este requerimiento: https://pypi.org/project/googletrans/
Para solucionar el error de la libreria se tiene que instalar un parche: https://stackoverflow.com/questions/52455774/googletrans-stopped-working-with-error-nonetype-object-has-no-attribute-group

29-10-2022
- Debido a que hay que separar el texto en oraciones para obtener la información necesario para formar el graph knowledge, necesitamos trocear los tweets por el caracter '.' o '\n'. Con las urls que contienen algunos de estos, el trabajo del troceo se complicaba. La solución ha sido eliminar estas urls, las cuales no aportan información al gráfico: https://github.com/Fhernd/PythonEjercicios/blob/master/Parte001/ex867_extraer_urls_texto.py
- Creo la primera versión del graph_knowledge.py: https://prateekjoshi.medium.com/knowledge-graph-a-powerful-data-science-technique-to-mine-information-from-text-with-python-f8bfd217accc

30-10-2022
- Al lanzar la ejecución de graph_knowledge.py vemos que en ciertos casos se obtiene como relación o como sujetos los iconos de los tweets. Es neceseario eliminar antes de proceder a obtener las relaciones y entidades: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python
Sigo modificando graph_knowledge.py hasta ir llegando a una versión final, cambios:
	- Eliminar entidades y relaciones vacías para que no se vean nodos separados o relaciones apuntando a nodos vacíos.
Me encuentro con el problema de que ahora mismo mi código solo recupera 100 tweets como máximo, habría que ver como ir paginando sobre twitter.

1-11-2022:
- Para la paginación de tweets encuentro la solución con el Cursor que proporciona Tweepy, para ello creamos un código que itera de 100 tweets en 100 tweets hasta llegar al número requerido: https://stackoverflow.com/questions/71041422/tweepys-api-search-tweets-is-only-giving-me-148-results

9-11-2022:
- Mejoras que incluir en el TFG después de hablar con David:
	- Separar la descarga de tweets con la creación del gráfico de conocimiento.
	- Almacenar estos tweets en una base de datos, la cual está en el remoto f-l2108-pc01.aulas.etsit.urjc.es en el puerto 21502. Es una base de datos en mongodb.
	- Crear la BD "TFG" donde iré guarando los tweets sobre colecciones que tendrán como nombre la query que usamos para buscar los tweets.
- Creo el archivo save_tweets.py, en el cual obtengo los tweets y las traducciones de estos a través de get_tweets_Cursor.py y translate.py y después se guardan en la base de datos "TFG" y en la Colección correspondiente: https://www.w3schools.com/python/python_mongodb_create_collection.asp.
	- El registro que se guarda en la BD tiene la siguiente forma:
		{tweet:'', user:'', date: ''}
		Se guarda el tweet, el usuario que lo escribe y la fecha en formato utc de cuando se publica el tweet.
- Para visualizar los datos de manera más gráfica uso la app 'Studio 3T Linux': https://studio3t.com/download-studio3t-free
- Queda pendiente hacer que el graph_knowledge.py recupere los tweets de la BD y muestre el gráfico.
- ¿Eliminar de los nodos y relaciones palabras que tengan el carcater # o @?

13-11-2022:
- Modificación del archivo graph_knowledge.py para que funcione a través de los tweets que carga de la base de datos y se eliminan aquellos nodos o relaciones que contengan el caracter @ o #: https://www.w3schools.com/python/python_mongodb_create_collection.asp.
- También he cambiado las trazas del archivo get_tweets_Cursor.py y translate.py. El archivo save_tweets.py usa estos dos archivos anteriores y es el que dura más tiempo en ejecución. La modificación es para que exista una mejor vista a nivel de usuario, por eso he implementado dos barras de carga para que se sepa cuánto tiempo queda de ejecución. La primera de ellas es una barra de carga de bloques de tweets que van de 100 en 100 y la segunda es una barra de carga que va de 1 en 1 traduciendo los tweets.


